""" Implementing AIR[1] for multi-MNIST, following Uber's tutorial: http://pyro.ai/examples/air.html
    and Adam Kosiorek's tutorial: http://akosiorek.github.io/ml/2017/09/03/implementing-air.html

    [1] Eslami et al., Attend, Infer, Repeat: Fast Scene Understanding with Generative Models
"""
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
from observations import multi_mnist
import torchvision

import matplotlib.pyplot as plt

import utils

batch_sz = 1 # TODO: for now, single batches
z_what_sz = 20

DEVICE = torch.device('cpu')
if torch.cuda.is_available():
    DEVICE = torch.device('cuda')

class Decoder(nn.Module):
    """ Takes latent vector z_what, describing a digit, and generates y_att. See Section 3 of [1]:

        "Each digit is obtained by first sampling a latent code z^{i}_{what} from the prior
        z^{i}_{what} ∼ N(0,1) and propagating it through a decoder network." [Eslami et al., 2016]
    """

    def __init__(self):
        super(Decoder, self).__init__()
        self.fc1 = nn.Linear(z_what_sz, 200)
        self.fc2 = nn.Linear(200, 400) # XXX: why does Uber output 20x20 digits?

    def forward(self, z_what):
        y_att = F.relu(self.fc1(z_what))
        y_att = F.sigmoid(self.fc2(y_att))
        return y_att

def stn(glimpse, z_where):
    # takes the small image generated by the neural network and places it within a larger image with the desired pose.
    m = glimpse.size(0) # batch size
    ### 1. expand z_where like so:
    ###   [s,x,y] -> [[s,0,x],
    ###               [0,s,y]]
    expansion_indices = torch.tensor([1, 0, 2, 0, 1, 3], dtype=torch.int64, device=DEVICE)
    theta = torch.cat([torch.zeros([1, 1], device=DEVICE).expand(m, 1), z_where], 1)
    theta = torch.index_select(theta, 1, expansion_indices).view(m, 2, 3)
    grid = F.affine_grid(theta, torch.Size((m, 1, 50, 50)))
    return F.grid_sample(glimpse.view(m, 1, 20, 20), grid)

# XXX: placeholders to show usage, will want to abstract/wrap this somehow later
z_where_loc = torch.Tensor([3.,0.,0.]).expand(batch_sz, -1) # expand along batch dim: m x 3
z_where_scale = torch.Tensor([0.1,1.,1.]).expand(batch_sz, -1) # same

def save_images(imgs, path):
    torchvision.utils.save_image(imgs.cpu(), path, pad_value=1.0)

def sample_glimpse_prior():
    ## XXX: right now, this is separate from geom_prior_step, but according to the authors'
    ##      explanation, it really is part of the same process

    z_where = np.random.normal(z_where_loc, z_where_scale, (batch_sz, 3))
    z_where = utils.to_var(torch.from_numpy(z_where).float())

    decode = Decoder().to(DEVICE)
    z_what = np.random.normal(0,1, (batch_sz, z_what_sz))
    z_what = utils.to_var(torch.from_numpy(z_what).float())

    y_att = decode(z_what)

    # Use STN to position/scale y_att within y, using z_where:
    y = stn(y_att, z_where)
    return y

def geom_prior_step(t, y_prev, z_pres_prev):
    """ The AIR inference network produces three sets of variables for each entity at every time-step:
          * a 1-dimensional Bernoulli variable indicating the entity’s presence (z^{i}_{pres})
          * a C-dimensional distributed vector describing its class or appearance (z^{i}_{what})
          * a 3-dimensional vector specifying the affine parameters of its position and scale (z^{i}_{where})
        [Eslami et al., 2016]
    """
    # z_pres: bernoulli random variable indicating if sampled digit should be included
    z_pres = np.random.binomial(1, 0.5 * z_pres_prev) # if z_pres_prev = 0, z_pres = 0
    z_pres = utils.to_var(torch.from_numpy(z_pres).float())
    y = sample_glimpse_prior() * z_pres # sample a single digit, according to z_pres

    return y_prev + y, z_pres

def geom_prior(n):
    # n: number of steps (3 in the paper)
    y = torch.zeros(batch_sz, 1, 50, 50, device=DEVICE)
    z_pres = torch.ones(batch_sz, 1, device=DEVICE)
    for t in range(n):
        y, z_pres = geom_prior_step(t, y, z_pres)
        save_images(y, "step_{}.png".format(t))
    return y

def main():
    x = torch.cat([sample_glimpse_prior() for _ in range(3)], 0)
    save_images(x, "step_sketch.png") # visualise each step independently
    y = geom_prior(3) # sample up to 3 digits
    save_images(y, "vis_samples.png")

if __name__ == "__main__":
    main()

